{
  "hash": "705a3d1e2e84fce86257f601fa2399b1",
  "result": {
    "markdown": "---\ntitle: \"Anomaly Detection Demonstrated in the Forest Cover Types Dataset\"\nauthor: \"Aruj Nayak\"\ndate: \"2023-12-06\"\ncategories: [Anomaly Detection]\nimage: \"anomaly.jpg\"\n---\n\n# Anomaly Detection Demonstrated in the Forest Cover Types Dataset\n\n# Introduction: \nUnderstanding Anomaly Detection is a vital component as it involves identifying patterns or instances that stand out from the majority of data points. Anomalies can signify potential fraud, errors, or abnormal behavior, making their detection critical for decision-making and data quality. In the vast landscape of data, anomalies or outliers can provide crucial insights or indicate potential issues. Thus, this field of Data Analysis specifically focuses on identifying these instances that deviate significantly from the norm within a dataset. This blog post introduces two popular anomaly detection methods: Local Outlier Factor (LOF) and Isolation Forest.\n\n# Local Outlier Factor Anomaly Detection Method: \nLocal Outlier Factor is a robust anomaly detection algorithm, evaluating the local density deviation of individual data points. This method operates by contrasting the density of a specific data point with that of its neighboring points. Instances demonstrating substantially lower density in comparison to their neighbors are assigned higher anomaly scores, signifying their likelihood of being outliers. LOF proves very effective in situations where anomalies are not necessarily far removed from the majority but exhibit a distinctive characteristic of lower density.\n\n# Isolation Forest Anomaly Detection Method: \nIsolation Forest takes a different approach by isolating anomalies rather than profiling normal instances. It constructs a tree-based structure, isolating anomalies in fewer steps due to their uniqueness. Anomalies are isolated more quickly in the tree, making the isolation path shorter. Isolation Forest is efficient, scalable, and often performs well on high-dimensional data.\n\n# Dataset: \nThe Forest Cover Types dataset is commonly used for classification tasks. It comprises of cartographic variables, including topography, soil types, and wilderness areas, to predict forest cover types. In our anomaly detection example, we consider a specific forest cover type as anomalies, aiming to detect unusual instances in the dataset.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nfrom sklearn.datasets import fetch_covtype\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\n# Loading the Forest Cover Types dataset\ncover_types = fetch_covtype()\ndata = pd.DataFrame(data=cover_types.data, columns=[f'feature_{i}' for i in range(cover_types.data.shape[1])])\ndata['target'] = cover_types.target\n```\n:::\n\n\nThe above section involves importing the required python libraries and loading the Forest Cover Types dataset using fetch_covtype. The data is then converted into a Pandas DataFrame for ease of manipulation.\n\nThe following code snippet demonstrates a specific forest cover type (type 1) as anomalies, creating separate datasets for normal and anomaly instances. A combined dataset is then formed for visualization, wich comprises of a subset of normal data and all anomaly data.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Simplifying by considering one forest cover type (e.g., type 1) as anomalies\n# This can be adjusted based on specific use cases\nanomaly_label = 1\nnormal_data = data[data['target'] != anomaly_label]\nanomaly_data = data[data['target'] == anomaly_label]\n\n# Combining a subset of normal data with anomaly data for visualization\nsubset_normal_data = normal_data.sample(n=1000, random_state=42)\ncombined_data = pd.concat([subset_normal_data, anomaly_data])\n```\n:::\n\n\nNext, Principal Component Analysis (PCA) is applied to reduce dimensionality of this dataset by reducing to two principal components, capturing the most significant variations.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Employing PCA for dimensionality reduction\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(combined_data.drop('target', axis=1))\n```\n:::\n\n\nFinally, the Isolation Forest is employed to visually represent the anomalies in a scatter plot using the reduced PCA space.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Applying Isolation Forest\nmodel_iforest = IsolationForest(contamination=0.05)\npredictions_iforest = model_iforest.fit_predict(combined_data.drop('target', axis=1))\n# Visualizing Isolation Forest results\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=predictions_iforest, cmap='viridis')\nplt.title('Isolation Forest Anomaly Detection')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nText(0, 0.5, 'Principal Component 2')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-2.png){width=498 height=523}\n:::\n:::\n\n\nAdditionally, a subplot is also created to compare the results obtained using Local Outlier Factor Method to show the difference between these two anomaly detection methods.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# Implementing Local Outlier Factor (LOF)\nmodel_lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\npredictions_lof = model_lof.fit_predict(combined_data.drop('target', axis=1))\n\n# Visualizing Local Outlier Factor results\nplt.subplot(1, 2, 2)\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=predictions_lof, cmap='viridis')\nplt.title('Local Outlier Factor Anomaly Detection')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){width=367 height=449}\n:::\n:::\n\n\nThus, anomaly detection proves indispensable in soil microbial analysis and forest coverage assessment, forging a critical link between its importance and the preservation of environmental ecosystems. By pinpointing irregularities in microbial dynamics or unexpected changes in forest vegetation through anomaly detection, we enhance our ability to detect potential threats early on.These methods demonstrate the broader importance of anomaly detection tehcniques in providing actionable insights for environmental conservation and ensuring the long-term health and resilience of ecosystems.\n\n# Source:\n\nImage is taken from- [https://anomify.ai/blogs/what-is-anomaly-detection](https://anomify.ai/blogs/what-is-anomaly-detection)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}