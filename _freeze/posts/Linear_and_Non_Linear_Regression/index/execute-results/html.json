{
  "hash": "940162744a9f95010a67e782e770bb06",
  "result": {
    "markdown": "---\ntitle: \"Linear and Non-Linear Regression\"\nauthor: \"Aruj Nayak\"\ndate: \"2023-12-06\"\ncategories: [Linear & Non-Linear Regression]\nimage: \"regression.jpg\"\n---\n\n# Exploring Linear and Non-linear Regression in Machine Learning\n\n# Introduction:\n\nLinear and non-linear regression are essential techniques in the realm of machine learning and statistics, commonly utilized for predicting numerical values based on input features. In this blog, we delve into the core concepts of linear and non-linear regression and provide practical examples using two prominent algorithms: Support Vector Machine (SVM) for linear regression and Gradient Boosting Regressor for non-linear regression.\n\n# Linear Regression:\n\nLinear regression is a straightforward and interpretable method used for modeling the relationship between a dependent variable and one or more independent variables. This method assumes a linear relationship, signifying that the change in the dependent variable is proportionate to the change in the independent variables. The equation for simple linear regression can be expressed as:\n\n\\[ y = mx + b \\]\n\nHere:\n- \\( y \\): Dependent variable\n- \\( x \\): Independent variable\n- \\( m \\): Slope of the line\n- \\( b \\): Y-intercept\n\n# Implementation:\nIn this blog, we implemented linear regression using the scikit-learn library with the Support Vector Machine (SVM) algorithm. In this context, SVM with a linear kernel functions as a linear regressor. We utilized the \"diamonds\" dataset from seaborn, considering attributes such as carat, depth, table, and dimensions (x, y, z) to predict diamond prices. The following code snippet demonstrates this-\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nimport seaborn as sns\n\n# Load the diamonds dataset\ndiamonds = sns.load_dataset(\"diamonds\")\n\n# Select features and target variable\nX = diamonds[['carat', 'depth', 'table', 'x', 'y', 'z']]\ny = diamonds['price']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the support vector regressor with linear kernel\nlinear_svm_model = SVR(kernel='linear')\nlinear_svm_model.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred_linear_svm = linear_svm_model.predict(X_test)\n\n# Evaluate the model\nr2_linear_svm=r2_score(y_test,y_pred_linear_svm)\nprint(f\"r2 score (Linear SVM): {r2_linear_svm}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nr2 score (Linear SVM): 0.7627450131825717\n```\n:::\n:::\n\n\nThe actual vs predicted labels for the test data predicted by this model can be visualized in order to understand how good our model is performing-\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Visualize predicted vs actual for linear regression\nplt.scatter(y_test, y_pred_linear_svm, alpha=0.5, label='Actual vs Predicted')\nplt.plot(np.unique(y_test), np.poly1d(np.polyfit(y_test, y_pred_linear_svm, 1))(np.unique(y_test)), color='red', label='Best Fit Line')\nplt.title(\"Linear Regression: Predicted vs Actual\")\nplt.xlabel(\"Actual Prices\")\nplt.ylabel(\"Predicted Prices\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=613 height=449}\n:::\n:::\n\n\n# Non-Linear Regression-\n\nWhile linear regression is effective for linear relationships, real-world scenarios often involve non-linear patterns. Non-linear regression extends the concept to model relationships where the change in the dependent variable is not proportional to the change in the independent variables.\n\n# Implementation-\n\nFor non-linear regression, we employed the Gradient Boosting Regressor, an ensemble method that combines weak learners to create a robust predictive model. Using the same \"diamonds\" dataset, this algorithm can capture intricate patterns in the data. Following code show the implementation of this model-\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import r2_score\n\n# Create and train the gradient boosting regressor\ngradient_boosting_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\ngradient_boosting_model.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred_gradient_boosting = gradient_boosting_model.predict(X_test)\n\n# Evaluate the model\nr2_gradient_boosting=r2_score(y_test,y_pred_gradient_boosting)\nprint(f\"r2 score (Gradient Boosting): {r2_gradient_boosting}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nr2 score (Gradient Boosting): 0.8863745168393169\n```\n:::\n:::\n\n\nAnd just like linear regression, we can visualize the predictions made by this model-\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Visualize predicted vs actual for non-linear regression\nplt.scatter(y_test, y_pred_gradient_boosting, alpha=0.5, label='Actual vs Predicted')\nplt.plot(np.unique(y_test), np.poly1d(np.polyfit(y_test, y_pred_gradient_boosting, 1))(np.unique(y_test)), color='red', label='Best Fit Line')\nplt.title(\"Non-linear Regression: Predicted vs Actual\")\nplt.xlabel(\"Actual Prices\")\nplt.ylabel(\"Predicted Prices\")\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){width=610 height=449}\n:::\n:::\n\n\n# Conclusion:\nThus, linear and non-linear regression are versatile tools for modeling relationships in data. Linear regression provides simplicity and interpretability, making it suitable for scenarios with linear dependencies. Conversely, non-linear regression techniques, like the Gradient Boosting Regressor, offer the flexibility to capture complex patterns in the data, making them valuable in various applications.\n\nWhen working with real-world datasets, understanding the nature of relationships within the data is crucial for choosing the appropriate regression model. Linear and non-linear regression methods complement each other, enabling data scientists and analysts to address a diverse array of predictive modeling tasks with precision and accuracy.\n\n# Source:\n\nThe image is taken from- [https://www.skillshare.com/en/classes/Data-Analysis-What-is-Non-Linear-Regression/694158109](https://www.skillshare.com/en/classes/Data-Analysis-What-is-Non-Linear-Regression/694158109)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}